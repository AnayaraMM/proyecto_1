{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt\n",
    "print(\"··· Instalación en el entorno finalizada ···\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49cd06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"df2015\": \"../data/2015.csv\",\n",
    "    \"df2016\": \"../data/2016.csv\",\n",
    "    \"df2017\": \"../data/2017.csv\",\n",
    "    \"df2018\": \"../data/2018.csv\",\n",
    "    \"df2019\": \"../data/2019.csv\"\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for name, path in files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=\",\")\n",
    "        datasets[name] = df\n",
    "        print(f\"{name} cargado correctamente ({len(df)} filas).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ha habido un error al cargar los datasets: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17819b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"df2015\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fe27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"df2016\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb928b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"df2017\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbfaccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"df2018\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e51642",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"df2019\"].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2966e1f3",
   "metadata": {},
   "source": [
    "Podemos comprobar que los datasets son bastante parecidos, tiene ligeras diferencias como la sintaxis del nombre de las columnas (Trust (Government Corruption) - Trust..Government.Corruption.) y que los datasets más actuales, 2018 y 2019 tienen menos columnas que años anteriores. Vamos comprobar si los tipos en las columnas siguen siendo iguales o han podido cambiar con el paso de los años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TIPOS DE DATOS DEL DATASET 2015\")\n",
    "print(datasets[\"df2015\"].dtypes)\n",
    "print(\"--------------------------------\")\n",
    "print(\"TIPOS DE DATOS DEL DATASET 2016\")\n",
    "print(datasets[\"df2016\"].dtypes)\n",
    "print(\"--------------------------------\")\n",
    "print(\"TIPOS DE DATOS DEL DATASET 2017\")\n",
    "print(datasets[\"df2017\"].dtypes)\n",
    "print(\"--------------------------------\")\n",
    "print(\"TIPOS DE DATOS DEL DATASET 2018\")\n",
    "print(datasets[\"df2018\"].dtypes)\n",
    "print(\"--------------------------------\")\n",
    "print(\"TIPOS DE DATOS DEL DATASET 2019\")\n",
    "print(datasets[\"df2019\"].dtypes)\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e86f11",
   "metadata": {},
   "source": [
    "Vamos primero a renombrar las columnas para poder tratar mejor la información en su colectivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eecad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015\n",
    "datasets[\"df2015\"] = datasets[\"df2015\"].rename(columns={\n",
    "    'Happiness Rank': 'Overall Rank', \n",
    "    'Happiness Score': 'Score', \n",
    "    'Economy (GDP per Capita)': 'GDP per Capita', \n",
    "    'Health (Life Expectancy)': 'Healthy Life Expectancy',\n",
    "    'Trust (Government Corruption)': 'Perceptions of Corruption',\n",
    "    'Freedom': 'Freedom to Make Life Choices',\n",
    "    'Family': 'Social Support'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f5df78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "datasets[\"df2016\"] = datasets[\"df2016\"].rename(columns={\n",
    "    'Happiness Rank': 'Overall Rank', \n",
    "    'Happiness Score': 'Score', \n",
    "    'Economy (GDP per Capita)': 'GDP per Capita', \n",
    "    'Health (Life Expectancy)': 'Healthy Life Expectancy',\n",
    "    'Trust (Government Corruption)': 'Perceptions of Corruption',\n",
    "    'Freedom': 'Freedom to Make Life Choices',\n",
    "    'Family': 'Social Support'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff82ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017\n",
    "datasets[\"df2017\"] = datasets[\"df2017\"].rename(columns={\n",
    "    'Country': 'Country or region',\n",
    "    'Happiness.Rank': 'Overall Rank',\n",
    "    'Happiness.Score': 'Score', \n",
    "    'Economy..GDP.per.Capita.': 'GDP per Capita', \n",
    "    'Health..Life.Expectancy.': 'Healthy Life Expectancy',\n",
    "    'Trust..Government.Corruption.': 'Perceptions of Corruption',\n",
    "    'Freedom': 'Freedom to Make Life Choices',\n",
    "    'Family': 'Social Support'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d3836",
   "metadata": {},
   "source": [
    "Para empezar lo que voy a hacer es juntar la columna country con la columna región, ya que veo que en 2018 y 2019 existe la columna \"Country or region\", además de ordenar las columnas para tenerlas en el mismo orden que el resto de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fea292",
   "metadata": {},
   "outputs": [],
   "source": [
    "media = datasets[\"df2015\"]['Score'].mean()\n",
    "error_estandar = datasets[\"df2015\"]['Standard Error'].max()\n",
    "print(f\"Proporción para: df2015: \", error_estandar / media)  \n",
    "\n",
    "# No es una proporción significativa, así que este campo lo eliminaremos del único dataset que lo tiene para homogenizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38148b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMPIEZA DE DATOS PARA EL 2015\n",
    "datasets[\"df2015\"][\"Country or region\"] = datasets[\"df2015\"][\"Country\"] + \" - \" + datasets[\"df2015\"][\"Region\"]\n",
    "datasets[\"df2015\"].insert(0, \"Country or region\", datasets[\"df2015\"].pop(\"Country or region\"))\n",
    "datasets[\"df2015\"].insert(0, \"Overall Rank\", datasets[\"df2015\"].pop(\"Overall Rank\"))\n",
    "datasets[\"df2015\"] = datasets[\"df2015\"].drop(columns=[\"Country\", \"Region\", \"Dystopia Residual\", \"Standard Error\"])\n",
    "datasets[\"df2015\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b4889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMPIEZA DE DATOS PARA EL 2016\n",
    "datasets[\"df2016\"][\"Country or region\"] = datasets[\"df2016\"][\"Country\"] + \" - \" + datasets[\"df2016\"][\"Region\"]\n",
    "datasets[\"df2016\"].insert(0, \"Country or region\", datasets[\"df2016\"].pop(\"Country or region\"))\n",
    "datasets[\"df2016\"].insert(0, \"Overall Rank\", datasets[\"df2016\"].pop(\"Overall Rank\"))\n",
    "datasets[\"df2016\"] = datasets[\"df2016\"].drop(columns=[\"Country\", \"Region\", \"Dystopia Residual\", \"Lower Confidence Interval\", \"Upper Confidence Interval\"])\n",
    "datasets[\"df2016\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMPIEZA DE DATOS PARA EL 2017\n",
    "datasets[\"df2017\"].insert(0, \"Overall Rank\", datasets[\"df2017\"].pop(\"Overall Rank\"))\n",
    "datasets[\"df2017\"] = datasets[\"df2017\"].drop(columns=[\"Dystopia.Residual\", \"Whisker.high\", \"Whisker.low\"])\n",
    "datasets[\"df2017\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797ae83",
   "metadata": {},
   "source": [
    "Nuestros datasets ya están complemente igualados en cuestión de columnas, comprobemos una vez más los tipos, ahora se verá con más claridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64939a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in datasets.items():\n",
    "    print(f\"Tipos de columnas en {name}:\")\n",
    "    print(df.dtypes)\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cdbdac",
   "metadata": {},
   "source": [
    "Empezaremos ahora comprobando los datos que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f6c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprobando valores nulos en df2015:\n",
      "Valores nulos encontrados: Series([], dtype: int64)\n",
      "----------------------------------------\n",
      "Comprobando valores nulos en df2016:\n",
      "Valores nulos encontrados: Series([], dtype: int64)\n",
      "----------------------------------------\n",
      "Comprobando valores nulos en df2017:\n",
      "Valores nulos encontrados: Series([], dtype: int64)\n",
      "----------------------------------------\n",
      "Comprobando valores nulos en df2018:\n",
      "Valores nulos encontrados: Perceptions of corruption    1\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Comprobando valores nulos en df2019:\n",
      "Valores nulos encontrados: Series([], dtype: int64)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, df in datasets.items():\n",
    "    print(f\"Comprobando valores nulos en {name}:\")\n",
    "    nulos_por_columna = datasets[name].isnull().sum()\n",
    "    nulos_por_columna = nulos_por_columna[nulos_por_columna > 0]\n",
    "    print(f\"Valores nulos encontrados: {nulos_por_columna}\")\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7337ef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posición:  (0, 'Overall rank')\n",
      "Fila del valor nulo: \n",
      " Overall rank                                      20\n",
      "Country or region               United Arab Emirates\n",
      "Score                                          6.774\n",
      "GDP per capita                                 2.096\n",
      "Social support                                 0.776\n",
      "Healthy life expectancy                         0.67\n",
      "Freedom to make life choices                   0.284\n",
      "Generosity                                     0.186\n",
      "Perceptions of corruption                      0.112\n",
      "Name: 19, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#C Como solo tenemos un valor nulo en el dataset de 2018 vamos a echar un ojo\n",
    "print(\"Posición: \", datasets[\"df2018\"].isnull().stack().idxmax())\n",
    "print(\"Fila del valor nulo: \\n\", datasets[\"df2018\"].loc[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a42f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 9)\n",
      "Media que se utilizará:  0.112\n",
      "Overall rank                    0\n",
      "Country or region               0\n",
      "Score                           0\n",
      "GDP per capita                  0\n",
      "Social support                  0\n",
      "Healthy life expectancy         0\n",
      "Freedom to make life choices    0\n",
      "Generosity                      0\n",
      "Perceptions of corruption       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(datasets[\"df2018\"].shape)\n",
    "# Hay 156 registros, utilizaremos la media de la columna para poder rellenarla\n",
    "print(\"Media que se utilizará: \", datasets[\"df2018\"][\"Perceptions of corruption\"].mean())\n",
    "datasets[\"df2018\"][\"Perceptions of corruption\"].fillna(datasets[\"df2018\"][\"Perceptions of corruption\"].mean(), inplace=True)\n",
    "print(datasets[\"df2018\"].isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
